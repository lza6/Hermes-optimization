import time
import asyncio
import os
import uuid
import json
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request, Response
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

from .config import config
from .database import init_db, close_pool, check_pool_health
from .utils.logger import logger
from .controllers import chat, admin
from .services.log_service import LogService, LogBatcher
from .services.provider_manager import ProviderManagerService
from .services.rate_limiter import SlidingWindowLimiter
from .services.cache_service import CacheService
from .services.circuit_breaker import circuit_breaker

# Rate Limiter Setup
limiter = Limiter(key_func=get_remote_address)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info(f"æ­£åœ¨åˆå§‹åŒ– Hermes AI ç½‘å…³ v{config.VERSION} (Cosmic-Genesis ç‰ˆ)...")
    await init_db()
    await LogService.initialize()
    
    # v3.0.0: åˆå§‹åŒ–ç¼“å­˜æœåŠ¡
    CacheService.initialize()
    
    # v3.0.0: å¯åŠ¨æ—¥å¿—æ‰¹é‡å†™å…¥å™¨
    await LogBatcher.start()
    
    # Start periodic sync task
    asyncio.create_task(ProviderManagerService.start_periodic_sync())
    
    logger.info(f"Fox Hermes v{config.VERSION} æ­£åœ¨è¿è¡Œï¼Œç«¯å£ï¼š{config.PORT} ğŸš€")
    logger.info(f"æ§åˆ¶ä¸­å¿ƒè®¿é—®åœ°å€ï¼šhttp://localhost:{config.PORT}/dashboard")
    
    yield
    
    # Shutdown - ä¼˜é›…å…³é—­æ¸…ç†èµ„æº
    logger.info("Hermes ç½‘å…³æ­£åœ¨å…³é—­...")
    
    # v3.0.0: åœæ­¢æ—¥å¿—æ‰¹é‡å†™å…¥å™¨
    await LogBatcher.stop()
    
    # å…³é—­ HTTP å®¢æˆ·ç«¯æ± 
    from .services.proxy_service import close_http_client
    await close_http_client()
    
    # å…³é—­æ•°æ®åº“è¿æ¥æ± 
    await close_pool()
    logger.info("æ¸…ç†å·¥ä½œå·²å®Œæˆã€‚ç¥æ‚¨æœ‰æ„‰å¿«çš„ä¸€å¤©! ğŸ‘‹")

app = FastAPI(lifespan=lifespan)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# v3.0.0: è¯·æ±‚è¿½è¸ª ID ä¸­é—´ä»¶
@app.middleware("http")
async def trace_middleware(request: Request, call_next):
    """ä¸ºæ¯ä¸ªè¯·æ±‚æ·»åŠ è¿½è¸ª ID"""
    trace_id = request.headers.get("X-Trace-ID") or str(uuid.uuid4())[:8]
    request.state.trace_id = trace_id
    
    response = await call_next(request)
    response.headers["X-Trace-ID"] = trace_id
    return response

# Global Request Logging Middleware
@app.middleware("http")
async def log_requests(request: Request, call_next):
    # Request Logger
    path = request.url.path
    if path == "/v1/chat/completions":
        start_time = int(time.time() * 1000)
        
        response = await call_next(request)
        
        duration = int(time.time() * 1000) - start_time
        status = response.status_code
        ip = request.client.host
        
        # Model extracted from request state (set in controller)
        model = getattr(request.state, "model", None)
        trace_id = getattr(request.state, "trace_id", "-")
        
        # v5.0.0: å®æ—¶æŒ‡æ ‡ä¸æŒä¹…åŒ–æ—¥å¿—åŒæ­¥
        try:
            await LogService.log_request(
                method=request.method,
                path=path,
                status=status,
                duration=duration,
                model=model,
                ip=ip
            )
            # è®°å½•å»¶è¿Ÿåˆ°å†…å­˜æ ·æœ¬
            LogService.record_latency(duration)
        except Exception as e:
            logger.error(f"æ—¥å¿—ä¸­é—´ä»¶å¼‚å¸¸: {e}")
        
        logger.info(f"[{trace_id}] [{status}] {request.method} {path} - {duration}ms")
        return response
        
    return await call_next(request)

# ========================================
# æ»‘åŠ¨çª—å£é™æµä¸­é—´ä»¶ (Sliding Window Rate Limiter)
# æ›¿ä»£ç®€å•è®¡æ•°å™¨ï¼Œæä¾›æ›´å¹³æ»‘çš„é™æµæ•ˆæœ
# ========================================
_rate_limiter = SlidingWindowLimiter(
    max_requests=int(os.getenv("RATE_LIMIT_MAX", 60)),
    window_seconds=int(os.getenv("RATE_LIMIT_WINDOW", 60)),
    slot_count=12  # 12ä¸ªæ§½ï¼Œæ¯æ§½5ç§’
)

@app.middleware("http")
async def global_rate_limit(request: Request, call_next):
    # è·³è¿‡é™æ€èµ„æºå’Œå¥åº·æ£€æŸ¥
    path = request.url.path
    if path.startswith("/logo") or path.startswith("/Hermes") or path == "/health":
        return await call_next(request)
    
    ip = request.client.host if request.client else "unknown"
    result = await _rate_limiter.check(ip)
    
    if not result.allowed:
        return Response(
            content="è¯·æ±‚é¢‘ç‡è¶…é™ (è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•)",
            status_code=429,
            headers={
                "Content-Type": "text/plain; charset=utf-8",
                "X-RateLimit-Limit": str(result.limit),
                "X-RateLimit-Remaining": "0",
                "X-RateLimit-Reset": str(result.reset_at),
                "Retry-After": str(result.retry_after)
            }
        )
    
    response = await call_next(request)
    
    # æ·»åŠ é™æµçŠ¶æ€å“åº”å¤´ï¼ˆä¾¿äºå®¢æˆ·ç«¯ç›‘æ§é…é¢ï¼‰
    response.headers["X-RateLimit-Limit"] = str(result.limit)
    response.headers["X-RateLimit-Remaining"] = str(result.remaining)
    response.headers["X-RateLimit-Reset"] = str(result.reset_at)
    
    return response


# å¥åº·æ£€æŸ¥ç«¯ç‚¹ (v4.0.0 å¢å¼º)
@app.get("/health")
async def health_check():
    """v4.0.0 å¢å¼ºç‰ˆå¥åº·æ£€æŸ¥ï¼šåŒ…å«æ–­è·¯å™¨ã€ä¾›åº”å•†ã€ç¼“å­˜çŠ¶æ€"""
    db_healthy = await check_pool_health()
    
    # v4.0.0: è·å–æ–­è·¯å™¨çŠ¶æ€æ‘˜è¦
    circuit_status = circuit_breaker.get_all_status()
    open_circuits = [k for k, v in circuit_status.items() if v.get("state") == "open"]
    half_open_circuits = [k for k, v in circuit_status.items() if v.get("state") == "half_open"]
    
    # v4.0.0: è·å–ä¾›åº”å•†çŠ¶æ€æ‘˜è¦
    try:
        providers = await ProviderManagerService.get_all()
        active_providers = len([p for p in providers if p.get("status") == "active"])
        total_providers = len(providers)
    except:
        active_providers = 0
        total_providers = 0
    
    # v4.0.0: è·å–å»¶è¿Ÿç»Ÿè®¡
    latency_stats = LogService.get_latency_percentiles()
    
    # åˆ¤æ–­æ•´ä½“å¥åº·çŠ¶æ€
    overall_status = "healthy"
    if not db_healthy:
        overall_status = "unhealthy"
    elif open_circuits or active_providers == 0:
        overall_status = "degraded"
    
    return {
        "status": overall_status,
        "version": config.VERSION,
        "database": {
            "connected": db_healthy
        },
        "circuit_breaker": {
            "total": len(circuit_status),
            "open": len(open_circuits),
            "half_open": len(half_open_circuits),
            "open_keys": open_circuits if open_circuits else None
        },
        "providers": {
            "active": active_providers,
            "total": total_providers
        },
        "latency": latency_stats,
        "cache": CacheService.get_all_stats()
    }


# ========================================
# SSE å®æ—¶æŒ‡æ ‡å¹¿æ’­ç«¯ç‚¹ (v5.0 COSMIC-GENESIS)
# ========================================
from fastapi.responses import StreamingResponse

@app.get("/admin/events")
async def sse_endpoint(request: Request):
    """
    SSE é€šé“ï¼šå‘å‰ç«¯æ¨é€å®æ—¶æŒ‡æ ‡å’Œç³»ç»Ÿäº‹ä»¶ã€‚
    """
    async def event_generator():
        queue = await LogService.subscribe()
        try:
            # å‘é€åˆå§‹çŠ¶æ€
            initial_data = json.dumps({
                "type": "init", 
                "data": LogService.get_realtime_stats(),
                "ts": time.time()
            })
            yield f"data: {initial_data}\n\n"
            
            while True:
                if await request.is_disconnected():
                    break
                
                try:
                    # ä½¿ç”¨ wait_for é˜²æ­¢æ— é™ç­‰å¾…ï¼Œä»¥ä¾¿æ£€æŸ¥è¿æ¥çŠ¶æ€
                    event = await asyncio.wait_for(queue.get(), timeout=5.0)
                    yield f"data: {event}\n\n"
                except asyncio.TimeoutError:
                    # å¿ƒè·³
                    yield ": ping\n\n"
                    
        finally:
            await LogService.unsubscribe(queue)

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

# Register Routers
app.include_router(chat.router)
app.include_router(admin.router)

from fastapi.templating import Jinja2Templates

# Setup Templates
templates = Jinja2Templates(directory="hermes/templates")

# UI Routes with Jinja2
@app.get("/dashboard")
async def dashboard(request: Request):
    return templates.TemplateResponse("dashboard.html", {"request": request})

@app.get("/logs")
async def logs(request: Request):
    return templates.TemplateResponse("logs.html", {"request": request})

@app.get("/settings")
async def settings(request: Request):
    return templates.TemplateResponse("settings.html", {"request": request})

@app.get("/metrics")
async def metrics(request: Request):
    return templates.TemplateResponse("metrics.html", {"request": request})

@app.get("/chat")
async def chat_ui(request: Request):
    return templates.TemplateResponse("chat.html", {"request": request})

@app.get("/")
async def root(request: Request):
    return templates.TemplateResponse("dashboard.html", {"request": request})

# Static Files (Serve logo, etc from public)
if os.path.exists("public"):
    app.mount("/", StaticFiles(directory="public", html=False), name="public")



if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=config.PORT)
